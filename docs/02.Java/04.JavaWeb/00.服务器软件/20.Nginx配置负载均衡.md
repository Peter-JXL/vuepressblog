---
title: Nginx配置负载均衡
date: 2023-04-17 09:52:11
permalink: /Nginx/F5/
categories:
  - Java
  - JavaWeb
  - 服务器软件
tags:
  - 
---
# 20.Nginx配置负载均衡

![](https://image.peterjxl.com/blog/248.JPG)

　　随着互联网信息的爆炸性增长，负载均衡（load balance）已经不再是一个很陌生的话题，顾名思义，负载均衡即是将负载分摊到不同的服务单元，既保证服务的可用性，又保证响应足够快，给用户很好的体验。快速增长的访问量和数据流量催生了各式各样的负载均衡产品，
<!-- more -->
　　很多专业的负载均衡硬件提供了很好的功能，但却价格不菲，这使得负载均衡软件大受欢迎，nginx 就是其中的一个，在 linux 下还有 LVS、Haproxy 等等服务可以提供负载均衡服务。

　　本文我们就通过Nginx来演示如何实现负载均衡。

　　‍

## 需求

　　浏览器地址栏输入地址 http://127.0.0.1/F5/a.html，负载均衡效果，平均分发到 8080和 8081 端口中

　　‍

## 准备工作

1. 准备两台 tomcat 服务器，一台 8080，一台 8081
2. 在两台 tomcat 里面 webapps 目录中，都创建F5文件夹，并在文件夹中创建页面 index.html，用于测试（注意内容要不同）

　　‍

```shell
cd /opt/apache-tomcat-9.0.73/webapps/
mkdir F5
echo '<h1>This is 8080 F5 Tomcat</h1>' > F5/index.html


cd /opt/tomcat8181/apache-tomcat-9.0.73/webapps/
mkdir F5
echo '<h1>This is 8081 F5 Tomcat</h1>' > F5/index.html
```

　　‍

　　然后分别访问8080和8081端口，测试能否正常访问

　　![](https://image.peterjxl.com/blog/image-20230328073426-ljn14ec.png)

　　‍

## Nginx配置负载均衡

　　在http全局块添加以下配置：

```nginx
upstream myserver {
	server 127.0.0.1:8080;
	server 127.0.0.1:8081;
}
```

　　‍

　　‍

　　server中添加一个location：

```nginx
server {
        location / {
            root   html;
            proxy_pass http://myserver;
            index  index.html index.htm;
        }
}
```

　　‍

　　重启Nginx

```nginx
./nginx -s reload
```

　　‍

　　访问测试：每隔一秒刷新下页面，发现轮流访问的是两个Tomcat下的项目的index.html（可通过页面展示内容区分）

　　![Nginx负载均衡测试](https://image.peterjxl.com/blog/Nginx负载均衡测试-20230328075145-5pmomxg.gif)

　　‍

　　‍

　　完整配置：

```nginx
worker_processes  1;

events {
    worker_connections  1024;
}

http {
    include       mime.types;
    default_type  application/octet-stream;
    sendfile        on;
    keepalive_timeout  65;

    upstream myserver {
	server	127.0.0.1:8080;
	server	127.0.0.1:8081;
    }

    server {
        listen       9001;
        server_name  localhost;
	
	location / {
		proxy_pass http://myserver;
	}

        location ~ /edu/ {
	    proxy_pass http://127.0.0.1:8080;
        }

        location ~ /vod/ {
	    proxy_pass http://127.0.0.1:8081;
        }

        error_page   500 502 503 504  /50x.html;

        location = /50x.html {
            root   html;
        }
    }

}
```

　　‍

　　‍

## 分配方式

　　Nginx 提供了几种分配方式（策略）：

1. 轮询（默认策略）：每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器挂了，能自动剔除，不会再分发请求到挂了的服务器
2. 权重：weight 代表权,重默认为 1,权重越高被分配的客户端越多。指定轮询几率，weight 和访问比率成正比，用于后端服务器性能不均的情况。例如：

    ```nginx
    upstream myserver {
        server 127.0.0.1:8080 weight=5;
        server 127.0.0.1:8081 weight=10;
    }
    ```

    第二个server比第一个多一倍。
3. ip_hash：每个请求按访问 ip 的 hash 结果分配，这样每个访客固定访问一个后端服务器，可以解决 session 的问题。 例如：

    ```nginx
    upstream myserver {
        ip_hash;
        server 127.0.0.1:8080 weight=5;
        server 127.0.0.1:8081 weight=10;
    }
    ```
4. fair方式：按后端服务器的响应时间来分配请求，响应时间短的优先分配

    ```nginx
    upstream myserver {
        server 127.0.0.1:8080;
        server 127.0.0.1:8081;
        fair;
    }
    ```

　　‍

　　‍
